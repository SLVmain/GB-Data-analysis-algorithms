{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Логистическая регрессия. Log Loss\n",
    "\n",
    "**задание 1:**\n",
    "\n",
    "Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код с урока\n",
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss1(y, y_pred):\n",
    "    #отловим нули и единицы\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 0:\n",
    "            y_pred[i] += 1e-10\n",
    "        elif y_pred[i] == 1:\n",
    "            y_pred[i] -= 1e-10\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**задание 2**\n",
    "\n",
    "Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00],\n",
       "       [-1.18181818e+00, -1.18181818e+00, -8.18181818e-01,\n",
       "        -1.18181818e+00, -4.54545455e-01, -1.54545455e+00,\n",
       "         2.72727273e-01,  2.09090909e+00, -1.18181818e+00,\n",
       "        -8.18181818e-01],\n",
       "       [-6.25205607e+02, -6.25056075e+02, -6.25018692e+02,\n",
       "        -6.25130841e+02, -6.24495327e+02, -6.24981308e+02,\n",
       "        -6.24457944e+02, -6.24084112e+02, -6.25242991e+02,\n",
       "        -6.24831776e+02],\n",
       "       [-1.25000000e+00, -1.25000000e+00, -7.50000000e-01,\n",
       "        -1.25000000e+00, -7.50000000e-01, -1.25000000e+00,\n",
       "        -2.50000000e-01, -2.50000000e-01, -1.25000000e+00,\n",
       "        -7.50000000e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def robust_scale(X):\n",
    "    X_rob = X.copy().astype(np.float64)\n",
    "    for i in range(X.shape[0]):\n",
    "        if i == 0:\n",
    "          continue\n",
    "        percentiles = np.percentile(X[i], (25.0, 75.0))\n",
    "        X_rob[i] = (X[i] - np.median(X[i])) / percentiles[1] - percentiles[0]\n",
    "    return X_rob\n",
    "X_rob = robust_scale(X)\n",
    "X_rob  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  код с урока\n",
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss1(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "    #if i % (iterations / 10) == 0:\n",
    "        #print(i, W, err)\n",
    "    return (i, W, err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,\n",
       " array([ 4.97752615e-01, -1.39608623e-01, -1.26874105e-03,  1.52249130e+00]),\n",
       " 0.607030536477691)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = eval_model(X_rob, y, iterations=1000, alpha=1e-5)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_optimal_alpha(X, y, epsilon):\n",
    "    err_border = float('inf')\n",
    "    for alpha in np.linspace(1e-7, 1e-2, num = 1000):\n",
    "        i, W, err = eval_model(X, y, iterations=1000, alpha=alpha)\n",
    "        if (err < err_border):\n",
    "            i_border = i\n",
    "            W_border = W\n",
    "            err_border = err\n",
    "            alpha_border = alpha\n",
    "    print(f\"для заданной точности {epsilon}\\nоптимальное количество итераций = {i_border}\\nоптимальная скорость обучения ={alpha_border}\\nпри них получаем W = {W_border} и logloss = {err_border}\")\n",
    "    return W_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "для заданной точности 0.0001\n",
      "оптимальное количество итераций = 1000\n",
      "оптимальная скорость обучения =2.011981981981982e-05\n",
      "при них получаем W = [ 4.97752377e-01 -1.40526364e-01 -1.26827263e-03  1.52279973e+00] и logloss = 0.606937925609538\n"
     ]
    }
   ],
   "source": [
    "W1 = gradient_descent_optimal_alpha(X_rob, y, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**задание 3:**\n",
    "\n",
    "Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    y_pred_proba = 1 / (1 + np.exp(-np.dot(W, X)))\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39013625, 0.39009113, 0.56545293, 0.39011369, 0.55269325,\n",
       "       0.40229216, 0.70489341, 0.64901979, 0.39014753, 0.56539468])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(W1,X_rob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**задание 4:**\n",
    "\n",
    "Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X, border=0.55):\n",
    "    y_pred_proba = calc_pred_proba(W, X)\n",
    "    y_pred_proba = y_pred_proba.copy()\n",
    "    y_pred_proba[y_pred_proba >= border] = 1\n",
    "    y_pred_proba[y_pred_proba < border] = 0\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = calc_pred(W1, X_rob, border=0.55)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**задание 5:**\n",
    "\n",
    "Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    res = (y_pred == y).sum()/len(y)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_matrix(y, y_pred):\n",
    "    TP = y[(y - y_pred) == 0].sum()\n",
    "    FP = ((y - y_pred) == -1).sum()\n",
    "    FN = ((y - y_pred) == 1).sum()\n",
    "    TN = (y[(y - y_pred) == 0]==0).sum()\n",
    "    \n",
    "    return np.array([[TP, FP], \n",
    "                     [FN, TN]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 1.],\n",
       "       [1., 4.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EM = error_matrix(y, Y_pred)\n",
    "EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_F1(y, y_pred):\n",
    "    TP = EM[0,0]\n",
    "    FP = EM[0,1]\n",
    "    FN = EM[1,0]\n",
    "    TN = EM[1,1]\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.8, 0.8000000000000002)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_F1(y, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**задание 6:**\n",
    "\n",
    "Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я думаю, что модель всегда может переобучиться. Так как нет никаких факторов, сдерживающих это переобучение. В таких случаях может помочь регуляризация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**задание 7:** *(опция)* \n",
    "\n",
    "Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-3.12577541e-01  3.38572409e-01 -1.07225151e-04 -5.00244879e-01] 0.735757159148055\n",
      "2000 [-3.12577266e-01  3.37690365e-01 -1.08253946e-04 -4.98928895e-01] 0.7356324155257699\n",
      "3000 [-3.12576990e-01  3.36810483e-01 -1.09285657e-04 -4.97612447e-01] 0.7355078005639856\n",
      "4000 [-3.12576713e-01  3.35932754e-01 -1.10320269e-04 -4.96295538e-01] 0.7353833133415323\n",
      "5000 [-3.12576436e-01  3.35057167e-01 -1.11357764e-04 -4.94978172e-01] 0.7352589529462417\n",
      "6000 [-3.12576157e-01  3.34183711e-01 -1.12398126e-04 -4.93660353e-01] 0.7351347184748633\n",
      "7000 [-3.12575877e-01  3.33312377e-01 -1.13441336e-04 -4.92342084e-01] 0.7350106090329855\n",
      "8000 [-3.12575597e-01  3.32443153e-01 -1.14487379e-04 -4.91023369e-01] 0.734886623734955\n",
      "9000 [-3.12575315e-01  3.31576029e-01 -1.15536238e-04 -4.89704212e-01] 0.7347627617037963\n",
      "10000 [-3.12575033e-01  3.30710996e-01 -1.16587896e-04 -4.88384616e-01] 0.7346390220711347\n"
     ]
    }
   ],
   "source": [
    "def eval_model_reg1(X, y, iterations, alpha=1e-4, lambda_=1e-8):\n",
    "    np.random.seed(15)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        y_pred = sigmoid(np.dot(W, X))\n",
    "        err = calc_logloss1(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T) + lambda_ * np.sign(W))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W\n",
    "W = eval_model_reg1(X_rob, y, iterations=10000, alpha=2.011981981981982e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-3.12577541e-01  3.38572409e-01 -1.07225152e-04 -5.00244879e-01] 0.7357571591604324\n",
      "2000 [-3.12577266e-01  3.37690365e-01 -1.08253946e-04 -4.98928895e-01] 0.7356324155505264\n",
      "3000 [-3.12576991e-01  3.36810483e-01 -1.09285658e-04 -4.97612447e-01] 0.7355078006011105\n",
      "4000 [-3.12576714e-01  3.35932755e-01 -1.10320270e-04 -4.96295538e-01] 0.7353833133910156\n",
      "5000 [-3.12576436e-01  3.35057168e-01 -1.11357765e-04 -4.94978172e-01] 0.7352589530080731\n",
      "6000 [-3.12576158e-01  3.34183712e-01 -1.12398127e-04 -4.93660353e-01] 0.7351347185490333\n",
      "7000 [-3.12575878e-01  3.33312377e-01 -1.13441338e-04 -4.92342085e-01] 0.7350106091194847\n",
      "8000 [-3.12575598e-01  3.32443154e-01 -1.14487381e-04 -4.91023370e-01] 0.7348866238337741\n",
      "9000 [-3.12575316e-01  3.31576030e-01 -1.15536240e-04 -4.89704213e-01] 0.7347627618149267\n",
      "10000 [-3.12575034e-01  3.30710997e-01 -1.16587898e-04 -4.88384617e-01] 0.7346390221945678\n"
     ]
    }
   ],
   "source": [
    "def eval_model_reg2(X, y, iterations, alpha=1e-4, lambda_=1e-8):\n",
    "    np.random.seed(15)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        y_pred = sigmoid(np.dot(W, X))\n",
    "        err = calc_logloss1(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T) + lambda_ * W)\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W\n",
    "W = eval_model_reg2(X_rob, y, iterations=10000, alpha=2.011981981981982e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
